{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"The grass is green .\" - 5 Tokens\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "# The sentence objects holds a sentence that we may want to embed or tag\n",
    "from flair.data import Sentence\n",
    "\n",
    "# Make a sentence object by passing a whitespace tokenized string\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# Print the object to see what's in there\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-30 11:27:55,953 Reading data from flair_datasets\n",
      "2019-01-30 11:27:55,954 Train: flair_datasets/corpus.csv\n",
      "2019-01-30 11:27:55,955 Dev: flair_datasets/dev_set.csv\n",
      "2019-01-30 11:27:55,955 Test: flair_datasets/test_set.csv\n"
     ]
    }
   ],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings,BertEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path\n",
    "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./flair_datasets/'), test_file='test_set.csv', dev_file='dev_set.csv', train_file='corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.adam import Adam\n",
    "word_embeddings = [WordEmbeddings('pt'), FlairEmbeddings('portuguese-forward'), FlairEmbeddings('portuguese-backward')]\n",
    "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=32, reproject_words=False, reproject_words_dimension=256, dropout=0.1234)\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
    "trainer = ModelTrainer(classifier, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-30 11:52:20,032 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:52:20,033 Evaluation method: MICRO_F1_SCORE\n",
      "2019-01-30 11:52:20,036 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:52:20,729 epoch 1 - iter 0/23 - loss 0.00133285\n",
      "2019-01-30 11:52:22,766 epoch 1 - iter 2/23 - loss 0.00121549\n",
      "2019-01-30 11:52:23,914 epoch 1 - iter 4/23 - loss 0.00124289\n",
      "2019-01-30 11:52:24,857 epoch 1 - iter 6/23 - loss 0.00132720\n",
      "2019-01-30 11:52:26,412 epoch 1 - iter 8/23 - loss 0.00133711\n",
      "2019-01-30 11:52:27,639 epoch 1 - iter 10/23 - loss 0.00128432\n",
      "2019-01-30 11:52:29,130 epoch 1 - iter 12/23 - loss 0.00128266\n",
      "2019-01-30 11:52:30,586 epoch 1 - iter 14/23 - loss 0.00130657\n",
      "2019-01-30 11:52:32,189 epoch 1 - iter 16/23 - loss 0.00130630\n",
      "2019-01-30 11:52:33,397 epoch 1 - iter 18/23 - loss 0.00130860\n",
      "2019-01-30 11:52:35,051 epoch 1 - iter 20/23 - loss 0.00130760\n",
      "2019-01-30 11:52:36,256 epoch 1 - iter 22/23 - loss 0.00133898\n",
      "2019-01-30 11:52:36,266 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:52:36,267 EPOCH 1 done: loss 0.0013 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 11:52:37,024 DEV  : loss 0.00178301 - f-score 0.8308 - acc 0.8308\n",
      "2019-01-30 11:52:38,062 TEST : loss 0.00151982 - f-score 0.8474 - acc 0.8474\n",
      "2019-01-30 11:52:50,511 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:52:50,992 epoch 2 - iter 0/23 - loss 0.00096374\n",
      "2019-01-30 11:52:52,098 epoch 2 - iter 2/23 - loss 0.00107376\n",
      "2019-01-30 11:52:53,366 epoch 2 - iter 4/23 - loss 0.00126231\n",
      "2019-01-30 11:52:54,348 epoch 2 - iter 6/23 - loss 0.00134500\n",
      "2019-01-30 11:52:55,871 epoch 2 - iter 8/23 - loss 0.00133491\n",
      "2019-01-30 11:52:56,798 epoch 2 - iter 10/23 - loss 0.00136477\n",
      "2019-01-30 11:52:58,781 epoch 2 - iter 12/23 - loss 0.00139059\n",
      "2019-01-30 11:53:00,434 epoch 2 - iter 14/23 - loss 0.00139099\n",
      "2019-01-30 11:53:01,765 epoch 2 - iter 16/23 - loss 0.00138352\n",
      "2019-01-30 11:53:03,047 epoch 2 - iter 18/23 - loss 0.00135987\n",
      "2019-01-30 11:53:04,279 epoch 2 - iter 20/23 - loss 0.00134800\n",
      "2019-01-30 11:53:05,538 epoch 2 - iter 22/23 - loss 0.00137158\n",
      "2019-01-30 11:53:05,549 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:53:05,550 EPOCH 2 done: loss 0.0014 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 11:53:06,298 DEV  : loss 0.00164488 - f-score 0.8608 - acc 0.8608\n",
      "2019-01-30 11:53:07,341 TEST : loss 0.00145280 - f-score 0.8665 - acc 0.8665\n",
      "2019-01-30 11:53:07,343 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:53:07,988 epoch 3 - iter 0/23 - loss 0.00124740\n",
      "2019-01-30 11:53:09,458 epoch 3 - iter 2/23 - loss 0.00107713\n",
      "2019-01-30 11:53:10,833 epoch 3 - iter 4/23 - loss 0.00106499\n",
      "2019-01-30 11:53:12,792 epoch 3 - iter 6/23 - loss 0.00109210\n",
      "2019-01-30 11:53:14,411 epoch 3 - iter 8/23 - loss 0.00109091\n",
      "2019-01-30 11:53:15,797 epoch 3 - iter 10/23 - loss 0.00110388\n",
      "2019-01-30 11:53:17,071 epoch 3 - iter 12/23 - loss 0.00113429\n",
      "2019-01-30 11:53:18,528 epoch 3 - iter 14/23 - loss 0.00116866\n",
      "2019-01-30 11:53:19,878 epoch 3 - iter 16/23 - loss 0.00120285\n",
      "2019-01-30 11:53:20,889 epoch 3 - iter 18/23 - loss 0.00125153\n",
      "2019-01-30 11:53:21,947 epoch 3 - iter 20/23 - loss 0.00129491\n",
      "2019-01-30 11:53:23,130 epoch 3 - iter 22/23 - loss 0.00133138\n",
      "2019-01-30 11:53:23,140 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:53:23,141 EPOCH 3 done: loss 0.0013 - lr 0.2000 - bad epochs 1\n",
      "2019-01-30 11:53:23,890 DEV  : loss 0.00160697 - f-score 0.8608 - acc 0.8608\n",
      "2019-01-30 11:53:24,932 TEST : loss 0.00138237 - f-score 0.8692 - acc 0.8692\n",
      "2019-01-30 11:53:37,284 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:53:38,212 epoch 4 - iter 0/23 - loss 0.00131869\n",
      "2019-01-30 11:53:40,048 epoch 4 - iter 2/23 - loss 0.00123947\n",
      "2019-01-30 11:53:42,051 epoch 4 - iter 4/23 - loss 0.00120223\n",
      "2019-01-30 11:53:43,203 epoch 4 - iter 6/23 - loss 0.00123024\n",
      "2019-01-30 11:53:44,602 epoch 4 - iter 8/23 - loss 0.00120649\n",
      "2019-01-30 11:53:45,767 epoch 4 - iter 10/23 - loss 0.00122160\n",
      "2019-01-30 11:53:47,312 epoch 4 - iter 12/23 - loss 0.00125226\n",
      "2019-01-30 11:53:48,664 epoch 4 - iter 14/23 - loss 0.00123774\n",
      "2019-01-30 11:53:49,880 epoch 4 - iter 16/23 - loss 0.00122755\n",
      "2019-01-30 11:53:51,204 epoch 4 - iter 18/23 - loss 0.00122409\n",
      "2019-01-30 11:53:52,384 epoch 4 - iter 20/23 - loss 0.00122072\n",
      "2019-01-30 11:53:53,401 epoch 4 - iter 22/23 - loss 0.00127213\n",
      "2019-01-30 11:53:53,411 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:53:53,412 EPOCH 4 done: loss 0.0013 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 11:53:54,163 DEV  : loss 0.00166416 - f-score 0.8649 - acc 0.8649\n",
      "2019-01-30 11:53:55,203 TEST : loss 0.00150965 - f-score 0.8610 - acc 0.8610\n",
      "2019-01-30 11:54:07,643 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:54:08,634 epoch 5 - iter 0/23 - loss 0.00118278\n",
      "2019-01-30 11:54:09,837 epoch 5 - iter 2/23 - loss 0.00119965\n",
      "2019-01-30 11:54:10,868 epoch 5 - iter 4/23 - loss 0.00124163\n",
      "2019-01-30 11:54:11,997 epoch 5 - iter 6/23 - loss 0.00125452\n",
      "2019-01-30 11:54:13,527 epoch 5 - iter 8/23 - loss 0.00131270\n",
      "2019-01-30 11:54:15,199 epoch 5 - iter 10/23 - loss 0.00141835\n",
      "2019-01-30 11:54:16,197 epoch 5 - iter 12/23 - loss 0.00153512\n",
      "2019-01-30 11:54:18,447 epoch 5 - iter 14/23 - loss 0.00150637\n",
      "2019-01-30 11:54:19,919 epoch 5 - iter 16/23 - loss 0.00147992\n",
      "2019-01-30 11:54:21,030 epoch 5 - iter 18/23 - loss 0.00146265\n",
      "2019-01-30 11:54:22,177 epoch 5 - iter 20/23 - loss 0.00152277\n",
      "2019-01-30 11:54:23,202 epoch 5 - iter 22/23 - loss 0.00152559\n",
      "2019-01-30 11:54:23,213 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:54:23,214 EPOCH 5 done: loss 0.0015 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 11:54:23,961 DEV  : loss 0.00173734 - f-score 0.8540 - acc 0.8540\n",
      "2019-01-30 11:54:25,007 TEST : loss 0.00161276 - f-score 0.8529 - acc 0.8529\n",
      "2019-01-30 11:54:25,010 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:54:25,605 epoch 6 - iter 0/23 - loss 0.00135301\n",
      "2019-01-30 11:54:26,979 epoch 6 - iter 2/23 - loss 0.00123752\n",
      "2019-01-30 11:54:28,503 epoch 6 - iter 4/23 - loss 0.00124937\n",
      "2019-01-30 11:54:29,780 epoch 6 - iter 6/23 - loss 0.00127456\n",
      "2019-01-30 11:54:30,960 epoch 6 - iter 8/23 - loss 0.00128641\n",
      "2019-01-30 11:54:32,046 epoch 6 - iter 10/23 - loss 0.00121618\n",
      "2019-01-30 11:54:33,483 epoch 6 - iter 12/23 - loss 0.00121668\n",
      "2019-01-30 11:54:35,039 epoch 6 - iter 14/23 - loss 0.00120429\n",
      "2019-01-30 11:54:36,949 epoch 6 - iter 16/23 - loss 0.00123018\n",
      "2019-01-30 11:54:38,347 epoch 6 - iter 18/23 - loss 0.00126840\n",
      "2019-01-30 11:54:39,466 epoch 6 - iter 20/23 - loss 0.00125898\n",
      "2019-01-30 11:54:40,648 epoch 6 - iter 22/23 - loss 0.00128607\n",
      "2019-01-30 11:54:40,659 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:54:40,660 EPOCH 6 done: loss 0.0013 - lr 0.2000 - bad epochs 1\n",
      "2019-01-30 11:54:41,424 DEV  : loss 0.00173916 - f-score 0.8445 - acc 0.8445\n",
      "2019-01-30 11:54:42,482 TEST : loss 0.00156773 - f-score 0.8515 - acc 0.8515\n",
      "2019-01-30 11:54:42,484 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:54:42,939 epoch 7 - iter 0/23 - loss 0.00141502\n",
      "2019-01-30 11:54:44,038 epoch 7 - iter 2/23 - loss 0.00126984\n",
      "2019-01-30 11:54:45,147 epoch 7 - iter 4/23 - loss 0.00121633\n",
      "2019-01-30 11:54:46,119 epoch 7 - iter 6/23 - loss 0.00124109\n",
      "2019-01-30 11:54:47,407 epoch 7 - iter 8/23 - loss 0.00122153\n",
      "2019-01-30 11:54:49,236 epoch 7 - iter 10/23 - loss 0.00118237\n",
      "2019-01-30 11:54:50,424 epoch 7 - iter 12/23 - loss 0.00118498\n",
      "2019-01-30 11:54:51,972 epoch 7 - iter 14/23 - loss 0.00118894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-30 11:54:53,893 epoch 7 - iter 16/23 - loss 0.00119061\n",
      "2019-01-30 11:54:55,346 epoch 7 - iter 18/23 - loss 0.00120072\n",
      "2019-01-30 11:54:56,491 epoch 7 - iter 20/23 - loss 0.00119377\n",
      "2019-01-30 11:54:57,767 epoch 7 - iter 22/23 - loss 0.00121432\n",
      "2019-01-30 11:54:57,778 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:54:57,779 EPOCH 7 done: loss 0.0012 - lr 0.2000 - bad epochs 2\n",
      "2019-01-30 11:54:58,530 DEV  : loss 0.00160282 - f-score 0.8636 - acc 0.8636\n",
      "2019-01-30 11:54:59,581 TEST : loss 0.00138193 - f-score 0.8706 - acc 0.8706\n",
      "2019-01-30 11:55:11,991 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:55:12,474 epoch 8 - iter 0/23 - loss 0.00107679\n",
      "2019-01-30 11:55:13,770 epoch 8 - iter 2/23 - loss 0.00104940\n",
      "2019-01-30 11:55:15,539 epoch 8 - iter 4/23 - loss 0.00104371\n",
      "2019-01-30 11:55:16,641 epoch 8 - iter 6/23 - loss 0.00109971\n",
      "2019-01-30 11:55:17,876 epoch 8 - iter 8/23 - loss 0.00112569\n",
      "2019-01-30 11:55:19,121 epoch 8 - iter 10/23 - loss 0.00114147\n",
      "2019-01-30 11:55:20,836 epoch 8 - iter 12/23 - loss 0.00111755\n",
      "2019-01-30 11:55:22,025 epoch 8 - iter 14/23 - loss 0.00111759\n",
      "2019-01-30 11:55:24,029 epoch 8 - iter 16/23 - loss 0.00114570\n",
      "2019-01-30 11:55:25,059 epoch 8 - iter 18/23 - loss 0.00115387\n",
      "2019-01-30 11:55:27,217 epoch 8 - iter 20/23 - loss 0.00117331\n",
      "2019-01-30 11:55:28,152 epoch 8 - iter 22/23 - loss 0.00121929\n",
      "2019-01-30 11:55:28,162 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:55:28,163 EPOCH 8 done: loss 0.0012 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 11:55:28,917 DEV  : loss 0.00158141 - f-score 0.8704 - acc 0.8704\n",
      "2019-01-30 11:55:29,964 TEST : loss 0.00141692 - f-score 0.8760 - acc 0.8760\n",
      "2019-01-30 11:55:29,967 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:55:30,456 epoch 9 - iter 0/23 - loss 0.00118415\n",
      "2019-01-30 11:55:31,928 epoch 9 - iter 2/23 - loss 0.00127559\n",
      "2019-01-30 11:55:32,928 epoch 9 - iter 4/23 - loss 0.00114579\n",
      "2019-01-30 11:55:35,179 epoch 9 - iter 6/23 - loss 0.00112039\n",
      "2019-01-30 11:55:36,430 epoch 9 - iter 8/23 - loss 0.00109792\n",
      "2019-01-30 11:55:37,881 epoch 9 - iter 10/23 - loss 0.00112238\n",
      "2019-01-30 11:55:39,229 epoch 9 - iter 12/23 - loss 0.00115817\n",
      "2019-01-30 11:55:40,700 epoch 9 - iter 14/23 - loss 0.00121195\n",
      "2019-01-30 11:55:41,872 epoch 9 - iter 16/23 - loss 0.00121941\n",
      "2019-01-30 11:55:43,824 epoch 9 - iter 18/23 - loss 0.00121797\n",
      "2019-01-30 11:55:45,252 epoch 9 - iter 20/23 - loss 0.00122348\n",
      "2019-01-30 11:55:46,183 epoch 9 - iter 22/23 - loss 0.00123160\n",
      "2019-01-30 11:55:46,193 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:55:46,193 EPOCH 9 done: loss 0.0012 - lr 0.2000 - bad epochs 1\n",
      "2019-01-30 11:55:46,940 DEV  : loss 0.00161731 - f-score 0.8690 - acc 0.8690\n",
      "2019-01-30 11:55:47,983 TEST : loss 0.00147917 - f-score 0.8719 - acc 0.8719\n",
      "2019-01-30 11:55:47,986 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:55:48,583 epoch 10 - iter 0/23 - loss 0.00098237\n",
      "2019-01-30 11:55:50,417 epoch 10 - iter 2/23 - loss 0.00110813\n",
      "2019-01-30 11:55:52,031 epoch 10 - iter 4/23 - loss 0.00114439\n",
      "2019-01-30 11:55:53,476 epoch 10 - iter 6/23 - loss 0.00114780\n",
      "2019-01-30 11:55:54,651 epoch 10 - iter 8/23 - loss 0.00119735\n",
      "2019-01-30 11:55:55,879 epoch 10 - iter 10/23 - loss 0.00124169\n",
      "2019-01-30 11:55:57,507 epoch 10 - iter 12/23 - loss 0.00121907\n",
      "2019-01-30 11:55:59,196 epoch 10 - iter 14/23 - loss 0.00119920\n",
      "2019-01-30 11:56:00,262 epoch 10 - iter 16/23 - loss 0.00117034\n",
      "2019-01-30 11:56:01,655 epoch 10 - iter 18/23 - loss 0.00116465\n",
      "2019-01-30 11:56:03,199 epoch 10 - iter 20/23 - loss 0.00116532\n",
      "2019-01-30 11:56:03,983 epoch 10 - iter 22/23 - loss 0.00120871\n",
      "2019-01-30 11:56:03,994 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:56:03,994 EPOCH 10 done: loss 0.0012 - lr 0.2000 - bad epochs 2\n",
      "2019-01-30 11:56:04,746 DEV  : loss 0.00209633 - f-score 0.8145 - acc 0.8145\n",
      "2019-01-30 11:56:05,790 TEST : loss 0.00191138 - f-score 0.8134 - acc 0.8134\n",
      "2019-01-30 11:56:18,152 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:56:19,169 epoch 11 - iter 0/23 - loss 0.00150184\n",
      "2019-01-30 11:56:20,453 epoch 11 - iter 2/23 - loss 0.00153168\n",
      "2019-01-30 11:56:22,048 epoch 11 - iter 4/23 - loss 0.00141841\n",
      "2019-01-30 11:56:23,077 epoch 11 - iter 6/23 - loss 0.00134476\n",
      "2019-01-30 11:56:24,266 epoch 11 - iter 8/23 - loss 0.00131127\n",
      "2019-01-30 11:56:25,942 epoch 11 - iter 10/23 - loss 0.00127470\n",
      "2019-01-30 11:56:27,821 epoch 11 - iter 12/23 - loss 0.00123491\n",
      "2019-01-30 11:56:29,490 epoch 11 - iter 14/23 - loss 0.00121616\n",
      "2019-01-30 11:56:30,941 epoch 11 - iter 16/23 - loss 0.00120495\n",
      "2019-01-30 11:56:32,225 epoch 11 - iter 18/23 - loss 0.00118582\n",
      "2019-01-30 11:56:33,141 epoch 11 - iter 20/23 - loss 0.00118236\n",
      "2019-01-30 11:56:34,083 epoch 11 - iter 22/23 - loss 0.00125782\n",
      "2019-01-30 11:56:34,093 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:56:34,094 EPOCH 11 done: loss 0.0013 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 11:56:34,843 DEV  : loss 0.00173785 - f-score 0.8377 - acc 0.8377\n",
      "2019-01-30 11:56:35,886 TEST : loss 0.00153298 - f-score 0.8433 - acc 0.8433\n",
      "2019-01-30 11:56:35,888 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:56:36,496 epoch 12 - iter 0/23 - loss 0.00101816\n",
      "2019-01-30 11:56:37,451 epoch 12 - iter 2/23 - loss 0.00101661\n",
      "2019-01-30 11:56:38,963 epoch 12 - iter 4/23 - loss 0.00096026\n",
      "2019-01-30 11:56:40,524 epoch 12 - iter 6/23 - loss 0.00100754\n",
      "2019-01-30 11:56:42,101 epoch 12 - iter 8/23 - loss 0.00105011\n",
      "2019-01-30 11:56:43,296 epoch 12 - iter 10/23 - loss 0.00109270\n",
      "2019-01-30 11:56:44,801 epoch 12 - iter 12/23 - loss 0.00113191\n",
      "2019-01-30 11:56:46,716 epoch 12 - iter 14/23 - loss 0.00116289\n",
      "2019-01-30 11:56:47,627 epoch 12 - iter 16/23 - loss 0.00116354\n",
      "2019-01-30 11:56:48,752 epoch 12 - iter 18/23 - loss 0.00118169\n",
      "2019-01-30 11:56:50,250 epoch 12 - iter 20/23 - loss 0.00117910\n",
      "2019-01-30 11:56:51,118 epoch 12 - iter 22/23 - loss 0.00120967\n",
      "2019-01-30 11:56:51,129 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:56:51,129 EPOCH 12 done: loss 0.0012 - lr 0.2000 - bad epochs 1\n",
      "2019-01-30 11:56:51,889 DEV  : loss 0.00154617 - f-score 0.8677 - acc 0.8677\n",
      "2019-01-30 11:56:52,939 TEST : loss 0.00135556 - f-score 0.8747 - acc 0.8747\n",
      "2019-01-30 11:56:52,941 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:56:53,586 epoch 13 - iter 0/23 - loss 0.00112791\n",
      "2019-01-30 11:56:54,834 epoch 13 - iter 2/23 - loss 0.00105227\n",
      "2019-01-30 11:56:56,034 epoch 13 - iter 4/23 - loss 0.00109371\n",
      "2019-01-30 11:56:57,808 epoch 13 - iter 6/23 - loss 0.00110256\n",
      "2019-01-30 11:56:59,038 epoch 13 - iter 8/23 - loss 0.00107783\n",
      "2019-01-30 11:57:00,464 epoch 13 - iter 10/23 - loss 0.00108672\n",
      "2019-01-30 11:57:02,166 epoch 13 - iter 12/23 - loss 0.00106300\n",
      "2019-01-30 11:57:03,495 epoch 13 - iter 14/23 - loss 0.00107781\n",
      "2019-01-30 11:57:04,437 epoch 13 - iter 16/23 - loss 0.00107133\n",
      "2019-01-30 11:57:05,849 epoch 13 - iter 18/23 - loss 0.00107850\n",
      "2019-01-30 11:57:07,616 epoch 13 - iter 20/23 - loss 0.00107587\n",
      "2019-01-30 11:57:08,607 epoch 13 - iter 22/23 - loss 0.00110959\n",
      "2019-01-30 11:57:08,617 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:57:08,618 EPOCH 13 done: loss 0.0011 - lr 0.2000 - bad epochs 2\n",
      "2019-01-30 11:57:09,366 DEV  : loss 0.00160172 - f-score 0.8649 - acc 0.8649\n",
      "2019-01-30 11:57:10,416 TEST : loss 0.00138700 - f-score 0.8678 - acc 0.8678\n",
      "2019-01-30 11:57:22,809 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:57:23,424 epoch 14 - iter 0/23 - loss 0.00111569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-30 11:57:24,765 epoch 14 - iter 2/23 - loss 0.00112912\n",
      "2019-01-30 11:57:26,361 epoch 14 - iter 4/23 - loss 0.00108184\n",
      "2019-01-30 11:57:28,244 epoch 14 - iter 6/23 - loss 0.00109034\n",
      "2019-01-30 11:57:29,574 epoch 14 - iter 8/23 - loss 0.00110588\n",
      "2019-01-30 11:57:31,238 epoch 14 - iter 10/23 - loss 0.00108817\n",
      "2019-01-30 11:57:32,399 epoch 14 - iter 12/23 - loss 0.00111275\n",
      "2019-01-30 11:57:33,433 epoch 14 - iter 14/23 - loss 0.00110210\n",
      "2019-01-30 11:57:34,859 epoch 14 - iter 16/23 - loss 0.00111193\n",
      "2019-01-30 11:57:36,364 epoch 14 - iter 18/23 - loss 0.00110212\n",
      "2019-01-30 11:57:37,677 epoch 14 - iter 20/23 - loss 0.00108497\n",
      "2019-01-30 11:57:38,546 epoch 14 - iter 22/23 - loss 0.00110449\n",
      "2019-01-30 11:57:38,557 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:57:38,558 EPOCH 14 done: loss 0.0011 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 11:57:39,311 DEV  : loss 0.00158244 - f-score 0.8608 - acc 0.8608\n",
      "2019-01-30 11:57:40,353 TEST : loss 0.00135150 - f-score 0.8747 - acc 0.8747\n",
      "2019-01-30 11:57:52,747 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:57:53,430 epoch 15 - iter 0/23 - loss 0.00118099\n",
      "2019-01-30 11:57:55,417 epoch 15 - iter 2/23 - loss 0.00104403\n",
      "2019-01-30 11:57:56,837 epoch 15 - iter 4/23 - loss 0.00102640\n",
      "2019-01-30 11:57:57,927 epoch 15 - iter 6/23 - loss 0.00104820\n",
      "2019-01-30 11:57:58,934 epoch 15 - iter 8/23 - loss 0.00104077\n",
      "2019-01-30 11:58:00,500 epoch 15 - iter 10/23 - loss 0.00103264\n",
      "2019-01-30 11:58:01,772 epoch 15 - iter 12/23 - loss 0.00105020\n",
      "2019-01-30 11:58:02,938 epoch 15 - iter 14/23 - loss 0.00105197\n",
      "2019-01-30 11:58:04,191 epoch 15 - iter 16/23 - loss 0.00106069\n",
      "2019-01-30 11:58:05,590 epoch 15 - iter 18/23 - loss 0.00111724\n",
      "2019-01-30 11:58:07,149 epoch 15 - iter 20/23 - loss 0.00111289\n",
      "2019-01-30 11:58:08,580 epoch 15 - iter 22/23 - loss 0.00113333\n",
      "2019-01-30 11:58:08,590 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:58:08,591 EPOCH 15 done: loss 0.0011 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 11:58:09,345 DEV  : loss 0.00151057 - f-score 0.8718 - acc 0.8718\n",
      "2019-01-30 11:58:10,390 TEST : loss 0.00132302 - f-score 0.8815 - acc 0.8815\n",
      "2019-01-30 11:58:10,392 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:58:11,710 epoch 16 - iter 0/23 - loss 0.00088178\n",
      "2019-01-30 11:58:13,155 epoch 16 - iter 2/23 - loss 0.00100084\n",
      "2019-01-30 11:58:14,703 epoch 16 - iter 4/23 - loss 0.00111129\n",
      "2019-01-30 11:58:16,117 epoch 16 - iter 6/23 - loss 0.00111278\n",
      "2019-01-30 11:58:17,128 epoch 16 - iter 8/23 - loss 0.00117022\n",
      "2019-01-30 11:58:18,763 epoch 16 - iter 10/23 - loss 0.00128062\n",
      "2019-01-30 11:58:19,970 epoch 16 - iter 12/23 - loss 0.00132032\n",
      "2019-01-30 11:58:21,295 epoch 16 - iter 14/23 - loss 0.00128924\n",
      "2019-01-30 11:58:22,588 epoch 16 - iter 16/23 - loss 0.00124514\n",
      "2019-01-30 11:58:24,261 epoch 16 - iter 18/23 - loss 0.00123944\n",
      "2019-01-30 11:58:25,819 epoch 16 - iter 20/23 - loss 0.00122748\n",
      "2019-01-30 11:58:26,751 epoch 16 - iter 22/23 - loss 0.00126391\n",
      "2019-01-30 11:58:26,762 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:58:26,763 EPOCH 16 done: loss 0.0013 - lr 0.2000 - bad epochs 1\n",
      "2019-01-30 11:58:27,514 DEV  : loss 0.00153846 - f-score 0.8690 - acc 0.8690\n",
      "2019-01-30 11:58:28,548 TEST : loss 0.00134483 - f-score 0.8733 - acc 0.8733\n",
      "2019-01-30 11:58:28,551 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:58:29,518 epoch 17 - iter 0/23 - loss 0.00093963\n",
      "2019-01-30 11:58:30,711 epoch 17 - iter 2/23 - loss 0.00104705\n",
      "2019-01-30 11:58:32,707 epoch 17 - iter 4/23 - loss 0.00097454\n",
      "2019-01-30 11:58:33,831 epoch 17 - iter 6/23 - loss 0.00096838\n",
      "2019-01-30 11:58:35,096 epoch 17 - iter 8/23 - loss 0.00099487\n",
      "2019-01-30 11:58:36,397 epoch 17 - iter 10/23 - loss 0.00097665\n",
      "2019-01-30 11:58:38,189 epoch 17 - iter 12/23 - loss 0.00100784\n",
      "2019-01-30 11:58:39,673 epoch 17 - iter 14/23 - loss 0.00100753\n",
      "2019-01-30 11:58:40,736 epoch 17 - iter 16/23 - loss 0.00103484\n",
      "2019-01-30 11:58:42,114 epoch 17 - iter 18/23 - loss 0.00105591\n",
      "2019-01-30 11:58:43,382 epoch 17 - iter 20/23 - loss 0.00106933\n",
      "2019-01-30 11:58:44,349 epoch 17 - iter 22/23 - loss 0.00108118\n",
      "2019-01-30 11:58:44,359 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:58:44,360 EPOCH 17 done: loss 0.0011 - lr 0.2000 - bad epochs 2\n",
      "2019-01-30 11:58:45,112 DEV  : loss 0.00154509 - f-score 0.8704 - acc 0.8704\n",
      "2019-01-30 11:58:46,163 TEST : loss 0.00135760 - f-score 0.8801 - acc 0.8801\n",
      "2019-01-30 11:58:58,534 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:58:59,046 epoch 18 - iter 0/23 - loss 0.00101406\n",
      "2019-01-30 11:59:00,106 epoch 18 - iter 2/23 - loss 0.00086213\n",
      "2019-01-30 11:59:02,158 epoch 18 - iter 4/23 - loss 0.00088929\n",
      "2019-01-30 11:59:03,774 epoch 18 - iter 6/23 - loss 0.00092714\n",
      "2019-01-30 11:59:05,004 epoch 18 - iter 8/23 - loss 0.00092597\n",
      "2019-01-30 11:59:06,584 epoch 18 - iter 10/23 - loss 0.00097711\n",
      "2019-01-30 11:59:08,489 epoch 18 - iter 12/23 - loss 0.00114112\n",
      "2019-01-30 11:59:09,989 epoch 18 - iter 14/23 - loss 0.00122693\n",
      "2019-01-30 11:59:11,454 epoch 18 - iter 16/23 - loss 0.00122342\n",
      "2019-01-30 11:59:12,457 epoch 18 - iter 18/23 - loss 0.00119893\n",
      "2019-01-30 11:59:13,709 epoch 18 - iter 20/23 - loss 0.00118778\n",
      "2019-01-30 11:59:14,468 epoch 18 - iter 22/23 - loss 0.00120573\n",
      "2019-01-30 11:59:14,478 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:59:14,479 EPOCH 18 done: loss 0.0012 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 11:59:15,223 DEV  : loss 0.00158521 - f-score 0.8690 - acc 0.8690\n",
      "2019-01-30 11:59:16,258 TEST : loss 0.00137625 - f-score 0.8678 - acc 0.8678\n",
      "2019-01-30 11:59:16,261 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:59:16,856 epoch 19 - iter 0/23 - loss 0.00120079\n",
      "2019-01-30 11:59:18,363 epoch 19 - iter 2/23 - loss 0.00109449\n",
      "2019-01-30 11:59:19,404 epoch 19 - iter 4/23 - loss 0.00101938\n",
      "2019-01-30 11:59:20,793 epoch 19 - iter 6/23 - loss 0.00105516\n",
      "2019-01-30 11:59:21,751 epoch 19 - iter 8/23 - loss 0.00108084\n",
      "2019-01-30 11:59:23,241 epoch 19 - iter 10/23 - loss 0.00106120\n",
      "2019-01-30 11:59:24,744 epoch 19 - iter 12/23 - loss 0.00102885\n",
      "2019-01-30 11:59:26,412 epoch 19 - iter 14/23 - loss 0.00102511\n",
      "2019-01-30 11:59:27,845 epoch 19 - iter 16/23 - loss 0.00102863\n",
      "2019-01-30 11:59:29,037 epoch 19 - iter 18/23 - loss 0.00102953\n",
      "2019-01-30 11:59:30,791 epoch 19 - iter 20/23 - loss 0.00102519\n",
      "2019-01-30 11:59:31,952 epoch 19 - iter 22/23 - loss 0.00104969\n",
      "2019-01-30 11:59:31,962 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:59:31,963 EPOCH 19 done: loss 0.0010 - lr 0.2000 - bad epochs 1\n",
      "2019-01-30 11:59:32,693 DEV  : loss 0.00151838 - f-score 0.8663 - acc 0.8663\n",
      "2019-01-30 11:59:33,760 TEST : loss 0.00129730 - f-score 0.8828 - acc 0.8828\n",
      "2019-01-30 11:59:46,098 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 11:59:46,653 epoch 20 - iter 0/23 - loss 0.00093671\n",
      "2019-01-30 11:59:47,828 epoch 20 - iter 2/23 - loss 0.00099115\n",
      "2019-01-30 11:59:49,346 epoch 20 - iter 4/23 - loss 0.00095571\n",
      "2019-01-30 11:59:50,502 epoch 20 - iter 6/23 - loss 0.00095505\n",
      "2019-01-30 11:59:52,497 epoch 20 - iter 8/23 - loss 0.00097571\n",
      "2019-01-30 11:59:53,568 epoch 20 - iter 10/23 - loss 0.00094421\n",
      "2019-01-30 11:59:55,091 epoch 20 - iter 12/23 - loss 0.00095897\n",
      "2019-01-30 11:59:56,340 epoch 20 - iter 14/23 - loss 0.00097714\n",
      "2019-01-30 11:59:57,614 epoch 20 - iter 16/23 - loss 0.00098949\n",
      "2019-01-30 11:59:59,671 epoch 20 - iter 18/23 - loss 0.00099199\n",
      "2019-01-30 12:00:01,209 epoch 20 - iter 20/23 - loss 0.00103408\n",
      "2019-01-30 12:00:02,063 epoch 20 - iter 22/23 - loss 0.00106818\n",
      "2019-01-30 12:00:02,073 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-30 12:00:02,074 EPOCH 20 done: loss 0.0011 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 12:00:02,832 DEV  : loss 0.00176568 - f-score 0.8649 - acc 0.8649\n",
      "2019-01-30 12:00:03,881 TEST : loss 0.00167244 - f-score 0.8583 - acc 0.8583\n",
      "2019-01-30 12:00:03,883 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:00:04,289 epoch 21 - iter 0/23 - loss 0.00124232\n",
      "2019-01-30 12:00:06,280 epoch 21 - iter 2/23 - loss 0.00117831\n",
      "2019-01-30 12:00:07,452 epoch 21 - iter 4/23 - loss 0.00112812\n",
      "2019-01-30 12:00:08,653 epoch 21 - iter 6/23 - loss 0.00111080\n",
      "2019-01-30 12:00:09,772 epoch 21 - iter 8/23 - loss 0.00108553\n",
      "2019-01-30 12:00:11,064 epoch 21 - iter 10/23 - loss 0.00107085\n",
      "2019-01-30 12:00:12,775 epoch 21 - iter 12/23 - loss 0.00106935\n",
      "2019-01-30 12:00:14,351 epoch 21 - iter 14/23 - loss 0.00105680\n",
      "2019-01-30 12:00:15,499 epoch 21 - iter 16/23 - loss 0.00105444\n",
      "2019-01-30 12:00:16,975 epoch 21 - iter 18/23 - loss 0.00103586\n",
      "2019-01-30 12:00:18,690 epoch 21 - iter 20/23 - loss 0.00104826\n",
      "2019-01-30 12:00:19,677 epoch 21 - iter 22/23 - loss 0.00106925\n",
      "2019-01-30 12:00:19,687 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:00:19,688 EPOCH 21 done: loss 0.0011 - lr 0.2000 - bad epochs 1\n",
      "2019-01-30 12:00:20,442 DEV  : loss 0.00156036 - f-score 0.8731 - acc 0.8731\n",
      "2019-01-30 12:00:21,491 TEST : loss 0.00136358 - f-score 0.8787 - acc 0.8787\n",
      "2019-01-30 12:00:21,493 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:00:22,188 epoch 22 - iter 0/23 - loss 0.00069647\n",
      "2019-01-30 12:00:23,989 epoch 22 - iter 2/23 - loss 0.00091411\n",
      "2019-01-30 12:00:25,579 epoch 22 - iter 4/23 - loss 0.00119300\n",
      "2019-01-30 12:00:27,082 epoch 22 - iter 6/23 - loss 0.00127387\n",
      "2019-01-30 12:00:28,210 epoch 22 - iter 8/23 - loss 0.00124130\n",
      "2019-01-30 12:00:29,097 epoch 22 - iter 10/23 - loss 0.00121515\n",
      "2019-01-30 12:00:30,353 epoch 22 - iter 12/23 - loss 0.00116628\n",
      "2019-01-30 12:00:31,948 epoch 22 - iter 14/23 - loss 0.00113381\n",
      "2019-01-30 12:00:33,281 epoch 22 - iter 16/23 - loss 0.00111115\n",
      "2019-01-30 12:00:34,602 epoch 22 - iter 18/23 - loss 0.00110489\n",
      "2019-01-30 12:00:36,036 epoch 22 - iter 20/23 - loss 0.00110250\n",
      "2019-01-30 12:00:37,497 epoch 22 - iter 22/23 - loss 0.00113909\n",
      "2019-01-30 12:00:37,509 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:00:37,510 EPOCH 22 done: loss 0.0011 - lr 0.2000 - bad epochs 2\n",
      "2019-01-30 12:00:38,271 DEV  : loss 0.00150537 - f-score 0.8690 - acc 0.8690\n",
      "2019-01-30 12:00:39,309 TEST : loss 0.00128554 - f-score 0.8883 - acc 0.8883\n",
      "2019-01-30 12:00:39,311 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:00:39,767 epoch 23 - iter 0/23 - loss 0.00105160\n",
      "2019-01-30 12:00:41,738 epoch 23 - iter 2/23 - loss 0.00103180\n",
      "2019-01-30 12:00:42,890 epoch 23 - iter 4/23 - loss 0.00101689\n",
      "2019-01-30 12:00:43,943 epoch 23 - iter 6/23 - loss 0.00096928\n",
      "2019-01-30 12:00:45,201 epoch 23 - iter 8/23 - loss 0.00100694\n",
      "2019-01-30 12:00:47,106 epoch 23 - iter 10/23 - loss 0.00098870\n",
      "2019-01-30 12:00:48,379 epoch 23 - iter 12/23 - loss 0.00096495\n",
      "2019-01-30 12:00:49,680 epoch 23 - iter 14/23 - loss 0.00096648\n",
      "2019-01-30 12:00:51,132 epoch 23 - iter 16/23 - loss 0.00095014\n",
      "2019-01-30 12:00:52,199 epoch 23 - iter 18/23 - loss 0.00096947\n",
      "2019-01-30 12:00:54,120 epoch 23 - iter 20/23 - loss 0.00096046\n",
      "2019-01-30 12:00:55,247 epoch 23 - iter 22/23 - loss 0.00098734\n",
      "2019-01-30 12:00:55,258 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:00:55,259 EPOCH 23 done: loss 0.0010 - lr 0.2000 - bad epochs 3\n",
      "2019-01-30 12:00:56,021 DEV  : loss 0.00156480 - f-score 0.8704 - acc 0.8704\n",
      "2019-01-30 12:00:57,066 TEST : loss 0.00134050 - f-score 0.8842 - acc 0.8842\n",
      "2019-01-30 12:01:09,505 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:01:10,537 epoch 24 - iter 0/23 - loss 0.00092317\n",
      "2019-01-30 12:01:11,744 epoch 24 - iter 2/23 - loss 0.00099110\n",
      "2019-01-30 12:01:13,355 epoch 24 - iter 4/23 - loss 0.00098851\n",
      "2019-01-30 12:01:15,006 epoch 24 - iter 6/23 - loss 0.00098026\n",
      "2019-01-30 12:01:16,475 epoch 24 - iter 8/23 - loss 0.00092733\n",
      "2019-01-30 12:01:18,322 epoch 24 - iter 10/23 - loss 0.00095607\n",
      "2019-01-30 12:01:19,742 epoch 24 - iter 12/23 - loss 0.00096830\n",
      "2019-01-30 12:01:21,261 epoch 24 - iter 14/23 - loss 0.00098359\n",
      "2019-01-30 12:01:22,540 epoch 24 - iter 16/23 - loss 0.00099980\n",
      "2019-01-30 12:01:24,178 epoch 24 - iter 18/23 - loss 0.00099275\n",
      "2019-01-30 12:01:25,351 epoch 24 - iter 20/23 - loss 0.00097651\n",
      "2019-01-30 12:01:26,020 epoch 24 - iter 22/23 - loss 0.00099199\n",
      "2019-01-30 12:01:26,030 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:01:26,031 EPOCH 24 done: loss 0.0010 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 12:01:26,797 DEV  : loss 0.00158500 - f-score 0.8786 - acc 0.8786\n",
      "2019-01-30 12:01:27,841 TEST : loss 0.00140915 - f-score 0.8856 - acc 0.8856\n",
      "2019-01-30 12:01:27,843 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:01:28,330 epoch 25 - iter 0/23 - loss 0.00077368\n",
      "2019-01-30 12:01:29,644 epoch 25 - iter 2/23 - loss 0.00087325\n",
      "2019-01-30 12:01:31,098 epoch 25 - iter 4/23 - loss 0.00085518\n",
      "2019-01-30 12:01:32,380 epoch 25 - iter 6/23 - loss 0.00080907\n",
      "2019-01-30 12:01:33,520 epoch 25 - iter 8/23 - loss 0.00084013\n",
      "2019-01-30 12:01:35,302 epoch 25 - iter 10/23 - loss 0.00086641\n",
      "2019-01-30 12:01:36,251 epoch 25 - iter 12/23 - loss 0.00089886\n",
      "2019-01-30 12:01:37,699 epoch 25 - iter 14/23 - loss 0.00089411\n",
      "2019-01-30 12:01:38,824 epoch 25 - iter 16/23 - loss 0.00091376\n",
      "2019-01-30 12:01:40,471 epoch 25 - iter 18/23 - loss 0.00093842\n",
      "2019-01-30 12:01:42,380 epoch 25 - iter 20/23 - loss 0.00095466\n",
      "2019-01-30 12:01:43,520 epoch 25 - iter 22/23 - loss 0.00097445\n",
      "2019-01-30 12:01:43,531 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:01:43,532 EPOCH 25 done: loss 0.0010 - lr 0.2000 - bad epochs 1\n",
      "2019-01-30 12:01:44,298 DEV  : loss 0.00159077 - f-score 0.8677 - acc 0.8677\n",
      "2019-01-30 12:01:45,356 TEST : loss 0.00137228 - f-score 0.8706 - acc 0.8706\n",
      "2019-01-30 12:01:57,730 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:01:58,242 epoch 26 - iter 0/23 - loss 0.00130716\n",
      "2019-01-30 12:01:59,632 epoch 26 - iter 2/23 - loss 0.00099694\n",
      "2019-01-30 12:02:01,068 epoch 26 - iter 4/23 - loss 0.00109661\n",
      "2019-01-30 12:02:02,288 epoch 26 - iter 6/23 - loss 0.00113529\n",
      "2019-01-30 12:02:03,424 epoch 26 - iter 8/23 - loss 0.00117535\n",
      "2019-01-30 12:02:05,290 epoch 26 - iter 10/23 - loss 0.00118375\n",
      "2019-01-30 12:02:06,931 epoch 26 - iter 12/23 - loss 0.00121476\n",
      "2019-01-30 12:02:08,425 epoch 26 - iter 14/23 - loss 0.00118213\n",
      "2019-01-30 12:02:09,888 epoch 26 - iter 16/23 - loss 0.00116264\n",
      "2019-01-30 12:02:11,420 epoch 26 - iter 18/23 - loss 0.00114488\n",
      "2019-01-30 12:02:12,729 epoch 26 - iter 20/23 - loss 0.00111158\n",
      "2019-01-30 12:02:13,935 epoch 26 - iter 22/23 - loss 0.00111971\n",
      "2019-01-30 12:02:13,947 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:02:13,947 EPOCH 26 done: loss 0.0011 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 12:02:14,702 DEV  : loss 0.00150712 - f-score 0.8745 - acc 0.8745\n",
      "2019-01-30 12:02:15,756 TEST : loss 0.00130906 - f-score 0.8896 - acc 0.8896\n",
      "2019-01-30 12:02:15,758 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:02:16,740 epoch 27 - iter 0/23 - loss 0.00091966\n",
      "2019-01-30 12:02:18,070 epoch 27 - iter 2/23 - loss 0.00086507\n",
      "2019-01-30 12:02:19,578 epoch 27 - iter 4/23 - loss 0.00089120\n",
      "2019-01-30 12:02:20,903 epoch 27 - iter 6/23 - loss 0.00094755\n",
      "2019-01-30 12:02:22,268 epoch 27 - iter 8/23 - loss 0.00094466\n",
      "2019-01-30 12:02:24,147 epoch 27 - iter 10/23 - loss 0.00090917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-30 12:02:25,591 epoch 27 - iter 12/23 - loss 0.00092801\n",
      "2019-01-30 12:02:26,687 epoch 27 - iter 14/23 - loss 0.00092765\n",
      "2019-01-30 12:02:28,117 epoch 27 - iter 16/23 - loss 0.00093644\n",
      "2019-01-30 12:02:29,302 epoch 27 - iter 18/23 - loss 0.00092217\n",
      "2019-01-30 12:02:30,829 epoch 27 - iter 20/23 - loss 0.00091400\n",
      "2019-01-30 12:02:31,821 epoch 27 - iter 22/23 - loss 0.00095238\n",
      "2019-01-30 12:02:31,832 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:02:31,832 EPOCH 27 done: loss 0.0010 - lr 0.2000 - bad epochs 1\n",
      "2019-01-30 12:02:32,591 DEV  : loss 0.00154624 - f-score 0.8622 - acc 0.8622\n",
      "2019-01-30 12:02:33,631 TEST : loss 0.00131814 - f-score 0.8774 - acc 0.8774\n",
      "2019-01-30 12:02:46,009 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:02:47,326 epoch 28 - iter 0/23 - loss 0.00085549\n",
      "2019-01-30 12:02:48,520 epoch 28 - iter 2/23 - loss 0.00086656\n",
      "2019-01-30 12:02:49,944 epoch 28 - iter 4/23 - loss 0.00088900\n",
      "2019-01-30 12:02:51,363 epoch 28 - iter 6/23 - loss 0.00090841\n",
      "2019-01-30 12:02:53,090 epoch 28 - iter 8/23 - loss 0.00087101\n",
      "2019-01-30 12:02:54,977 epoch 28 - iter 10/23 - loss 0.00084069\n",
      "2019-01-30 12:02:56,449 epoch 28 - iter 12/23 - loss 0.00087504\n",
      "2019-01-30 12:02:57,332 epoch 28 - iter 14/23 - loss 0.00086864\n",
      "2019-01-30 12:02:58,781 epoch 28 - iter 16/23 - loss 0.00086399\n",
      "2019-01-30 12:03:00,073 epoch 28 - iter 18/23 - loss 0.00087974\n",
      "2019-01-30 12:03:01,191 epoch 28 - iter 20/23 - loss 0.00089379\n",
      "2019-01-30 12:03:02,005 epoch 28 - iter 22/23 - loss 0.00091492\n",
      "2019-01-30 12:03:02,015 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:03:02,017 EPOCH 28 done: loss 0.0009 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 12:03:02,790 DEV  : loss 0.00160045 - f-score 0.8513 - acc 0.8513\n",
      "2019-01-30 12:03:03,837 TEST : loss 0.00139388 - f-score 0.8665 - acc 0.8665\n",
      "2019-01-30 12:03:16,233 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:03:17,063 epoch 29 - iter 0/23 - loss 0.00110969\n",
      "2019-01-30 12:03:18,332 epoch 29 - iter 2/23 - loss 0.00128821\n",
      "2019-01-30 12:03:19,928 epoch 29 - iter 4/23 - loss 0.00132037\n",
      "2019-01-30 12:03:21,429 epoch 29 - iter 6/23 - loss 0.00123195\n",
      "2019-01-30 12:03:22,711 epoch 29 - iter 8/23 - loss 0.00114703\n",
      "2019-01-30 12:03:24,113 epoch 29 - iter 10/23 - loss 0.00110570\n",
      "2019-01-30 12:03:25,430 epoch 29 - iter 12/23 - loss 0.00109493\n",
      "2019-01-30 12:03:26,467 epoch 29 - iter 14/23 - loss 0.00109631\n",
      "2019-01-30 12:03:27,912 epoch 29 - iter 16/23 - loss 0.00107053\n",
      "2019-01-30 12:03:29,153 epoch 29 - iter 18/23 - loss 0.00104225\n",
      "2019-01-30 12:03:31,182 epoch 29 - iter 20/23 - loss 0.00101908\n",
      "2019-01-30 12:03:32,586 epoch 29 - iter 22/23 - loss 0.00104491\n",
      "2019-01-30 12:03:32,596 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:03:32,597 EPOCH 29 done: loss 0.0010 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 12:03:33,343 DEV  : loss 0.00151166 - f-score 0.8799 - acc 0.8799\n",
      "2019-01-30 12:03:34,387 TEST : loss 0.00133184 - f-score 0.8924 - acc 0.8924\n",
      "2019-01-30 12:03:34,390 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:03:35,402 epoch 30 - iter 0/23 - loss 0.00092008\n",
      "2019-01-30 12:03:36,676 epoch 30 - iter 2/23 - loss 0.00086374\n",
      "2019-01-30 12:03:38,148 epoch 30 - iter 4/23 - loss 0.00090825\n",
      "2019-01-30 12:03:39,776 epoch 30 - iter 6/23 - loss 0.00087701\n",
      "2019-01-30 12:03:40,960 epoch 30 - iter 8/23 - loss 0.00085838\n",
      "2019-01-30 12:03:42,190 epoch 30 - iter 10/23 - loss 0.00087516\n",
      "2019-01-30 12:03:44,148 epoch 30 - iter 12/23 - loss 0.00089501\n",
      "2019-01-30 12:03:45,758 epoch 30 - iter 14/23 - loss 0.00087204\n",
      "2019-01-30 12:03:47,078 epoch 30 - iter 16/23 - loss 0.00088202\n",
      "2019-01-30 12:03:48,360 epoch 30 - iter 18/23 - loss 0.00087586\n",
      "2019-01-30 12:03:49,245 epoch 30 - iter 20/23 - loss 0.00086923\n",
      "2019-01-30 12:03:49,953 epoch 30 - iter 22/23 - loss 0.00087978\n",
      "2019-01-30 12:03:49,964 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:03:49,965 EPOCH 30 done: loss 0.0009 - lr 0.2000 - bad epochs 1\n",
      "2019-01-30 12:03:50,711 DEV  : loss 0.00164757 - f-score 0.8731 - acc 0.8731\n",
      "2019-01-30 12:03:51,765 TEST : loss 0.00147839 - f-score 0.8787 - acc 0.8787\n",
      "2019-01-30 12:04:04,116 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:04:04,575 epoch 31 - iter 0/23 - loss 0.00090617\n",
      "2019-01-30 12:04:05,905 epoch 31 - iter 2/23 - loss 0.00082007\n",
      "2019-01-30 12:04:07,189 epoch 31 - iter 4/23 - loss 0.00090614\n",
      "2019-01-30 12:04:08,909 epoch 31 - iter 6/23 - loss 0.00088479\n",
      "2019-01-30 12:04:10,185 epoch 31 - iter 8/23 - loss 0.00086405\n",
      "2019-01-30 12:04:12,154 epoch 31 - iter 10/23 - loss 0.00085125\n",
      "2019-01-30 12:04:13,209 epoch 31 - iter 12/23 - loss 0.00086719\n",
      "2019-01-30 12:04:14,243 epoch 31 - iter 14/23 - loss 0.00087105\n",
      "2019-01-30 12:04:16,249 epoch 31 - iter 16/23 - loss 0.00088982\n",
      "2019-01-30 12:04:17,441 epoch 31 - iter 18/23 - loss 0.00090913\n",
      "2019-01-30 12:04:18,907 epoch 31 - iter 20/23 - loss 0.00093120\n",
      "2019-01-30 12:04:19,660 epoch 31 - iter 22/23 - loss 0.00095109\n",
      "2019-01-30 12:04:19,670 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:04:19,671 EPOCH 31 done: loss 0.0010 - lr 0.2000 - bad epochs 0\n",
      "2019-01-30 12:04:20,429 DEV  : loss 0.00158882 - f-score 0.8759 - acc 0.8759\n",
      "2019-01-30 12:04:21,475 TEST : loss 0.00142470 - f-score 0.8801 - acc 0.8801\n",
      "2019-01-30 12:04:21,477 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:04:22,000 epoch 32 - iter 0/23 - loss 0.00094198\n",
      "2019-01-30 12:04:23,076 epoch 32 - iter 2/23 - loss 0.00093413\n",
      "2019-01-30 12:04:24,563 epoch 32 - iter 4/23 - loss 0.00080617\n",
      "2019-01-30 12:04:25,999 epoch 32 - iter 6/23 - loss 0.00078862\n",
      "2019-01-30 12:04:27,939 epoch 32 - iter 8/23 - loss 0.00088531\n",
      "2019-01-30 12:04:29,767 epoch 32 - iter 10/23 - loss 0.00093686\n",
      "2019-01-30 12:04:31,088 epoch 32 - iter 12/23 - loss 0.00090725\n",
      "2019-01-30 12:04:32,411 epoch 32 - iter 14/23 - loss 0.00089657\n",
      "2019-01-30 12:04:33,830 epoch 32 - iter 16/23 - loss 0.00088673\n",
      "2019-01-30 12:04:35,080 epoch 32 - iter 18/23 - loss 0.00087813\n",
      "2019-01-30 12:04:36,222 epoch 32 - iter 20/23 - loss 0.00087823\n",
      "2019-01-30 12:04:37,046 epoch 32 - iter 22/23 - loss 0.00091387\n",
      "2019-01-30 12:04:37,057 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:04:37,058 EPOCH 32 done: loss 0.0009 - lr 0.2000 - bad epochs 1\n",
      "2019-01-30 12:04:37,815 DEV  : loss 0.00181381 - f-score 0.8527 - acc 0.8527\n",
      "2019-01-30 12:04:38,853 TEST : loss 0.00160821 - f-score 0.8542 - acc 0.8542\n",
      "2019-01-30 12:04:38,856 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:04:39,413 epoch 33 - iter 0/23 - loss 0.00100526\n",
      "2019-01-30 12:04:41,354 epoch 33 - iter 2/23 - loss 0.00096931\n",
      "2019-01-30 12:04:42,887 epoch 33 - iter 4/23 - loss 0.00092380\n",
      "2019-01-30 12:04:44,359 epoch 33 - iter 6/23 - loss 0.00089358\n",
      "2019-01-30 12:04:46,286 epoch 33 - iter 8/23 - loss 0.00089911\n",
      "2019-01-30 12:04:47,441 epoch 33 - iter 10/23 - loss 0.00090247\n",
      "2019-01-30 12:04:48,542 epoch 33 - iter 12/23 - loss 0.00090214\n",
      "2019-01-30 12:04:49,648 epoch 33 - iter 14/23 - loss 0.00089953\n",
      "2019-01-30 12:04:50,981 epoch 33 - iter 16/23 - loss 0.00088983\n",
      "2019-01-30 12:04:52,420 epoch 33 - iter 18/23 - loss 0.00089754\n",
      "2019-01-30 12:04:53,913 epoch 33 - iter 20/23 - loss 0.00087933\n",
      "2019-01-30 12:04:55,196 epoch 33 - iter 22/23 - loss 0.00090317\n",
      "2019-01-30 12:04:55,207 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:04:55,207 EPOCH 33 done: loss 0.0009 - lr 0.2000 - bad epochs 2\n",
      "2019-01-30 12:04:55,965 DEV  : loss 0.00152897 - f-score 0.8690 - acc 0.8690\n",
      "2019-01-30 12:04:57,013 TEST : loss 0.00128013 - f-score 0.8883 - acc 0.8883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-30 12:04:57,015 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:04:57,971 epoch 34 - iter 0/23 - loss 0.00072811\n",
      "2019-01-30 12:04:59,953 epoch 34 - iter 2/23 - loss 0.00084808\n",
      "2019-01-30 12:05:01,595 epoch 34 - iter 4/23 - loss 0.00083068\n",
      "2019-01-30 12:05:03,253 epoch 34 - iter 6/23 - loss 0.00088090\n",
      "2019-01-30 12:05:04,230 epoch 34 - iter 8/23 - loss 0.00085664\n",
      "2019-01-30 12:05:05,345 epoch 34 - iter 10/23 - loss 0.00084794\n",
      "2019-01-30 12:05:06,882 epoch 34 - iter 12/23 - loss 0.00082674\n",
      "2019-01-30 12:05:08,015 epoch 34 - iter 14/23 - loss 0.00081210\n",
      "2019-01-30 12:05:09,407 epoch 34 - iter 16/23 - loss 0.00081867\n",
      "2019-01-30 12:05:10,587 epoch 34 - iter 18/23 - loss 0.00081927\n",
      "2019-01-30 12:05:11,500 epoch 34 - iter 20/23 - loss 0.00084680\n",
      "2019-01-30 12:05:12,238 epoch 34 - iter 22/23 - loss 0.00094440\n",
      "2019-01-30 12:05:12,248 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:05:12,249 EPOCH 34 done: loss 0.0009 - lr 0.2000 - bad epochs 3\n",
      "2019-01-30 12:05:12,997 DEV  : loss 0.00211227 - f-score 0.8267 - acc 0.8267\n",
      "2019-01-30 12:05:14,042 TEST : loss 0.00215143 - f-score 0.8270 - acc 0.8270\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-01.\n",
      "2019-01-30 12:05:14,044 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:05:14,650 epoch 35 - iter 0/23 - loss 0.00167397\n",
      "2019-01-30 12:05:15,912 epoch 35 - iter 2/23 - loss 0.00105412\n",
      "2019-01-30 12:05:17,280 epoch 35 - iter 4/23 - loss 0.00095756\n",
      "2019-01-30 12:05:18,744 epoch 35 - iter 6/23 - loss 0.00093252\n",
      "2019-01-30 12:05:20,218 epoch 35 - iter 8/23 - loss 0.00092780\n",
      "2019-01-30 12:05:21,540 epoch 35 - iter 10/23 - loss 0.00090522\n",
      "2019-01-30 12:05:22,883 epoch 35 - iter 12/23 - loss 0.00088498\n",
      "2019-01-30 12:05:25,204 epoch 35 - iter 14/23 - loss 0.00087405\n",
      "2019-01-30 12:05:26,238 epoch 35 - iter 16/23 - loss 0.00086138\n",
      "2019-01-30 12:05:27,581 epoch 35 - iter 18/23 - loss 0.00084941\n",
      "2019-01-30 12:05:28,899 epoch 35 - iter 20/23 - loss 0.00085399\n",
      "2019-01-30 12:05:29,846 epoch 35 - iter 22/23 - loss 0.00087596\n",
      "2019-01-30 12:05:29,856 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:05:29,857 EPOCH 35 done: loss 0.0009 - lr 0.1000 - bad epochs 0\n",
      "2019-01-30 12:05:30,618 DEV  : loss 0.00151325 - f-score 0.8636 - acc 0.8636\n",
      "2019-01-30 12:05:31,663 TEST : loss 0.00125055 - f-score 0.8910 - acc 0.8910\n",
      "2019-01-30 12:05:44,055 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:05:44,617 epoch 36 - iter 0/23 - loss 0.00087381\n",
      "2019-01-30 12:05:46,032 epoch 36 - iter 2/23 - loss 0.00087437\n",
      "2019-01-30 12:05:47,399 epoch 36 - iter 4/23 - loss 0.00084095\n",
      "2019-01-30 12:05:48,529 epoch 36 - iter 6/23 - loss 0.00079927\n",
      "2019-01-30 12:05:50,106 epoch 36 - iter 8/23 - loss 0.00080385\n",
      "2019-01-30 12:05:52,424 epoch 36 - iter 10/23 - loss 0.00083068\n",
      "2019-01-30 12:05:53,826 epoch 36 - iter 12/23 - loss 0.00080358\n",
      "2019-01-30 12:05:55,260 epoch 36 - iter 14/23 - loss 0.00082698\n",
      "2019-01-30 12:05:56,906 epoch 36 - iter 16/23 - loss 0.00081466\n",
      "2019-01-30 12:05:58,098 epoch 36 - iter 18/23 - loss 0.00080913\n",
      "2019-01-30 12:05:59,226 epoch 36 - iter 20/23 - loss 0.00080376\n",
      "2019-01-30 12:06:00,217 epoch 36 - iter 22/23 - loss 0.00081927\n",
      "2019-01-30 12:06:00,228 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:06:00,229 EPOCH 36 done: loss 0.0008 - lr 0.1000 - bad epochs 0\n",
      "2019-01-30 12:06:01,000 DEV  : loss 0.00150741 - f-score 0.8718 - acc 0.8718\n",
      "2019-01-30 12:06:02,053 TEST : loss 0.00124801 - f-score 0.8896 - acc 0.8896\n",
      "2019-01-30 12:06:14,466 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:06:15,236 epoch 37 - iter 0/23 - loss 0.00083676\n",
      "2019-01-30 12:06:16,358 epoch 37 - iter 2/23 - loss 0.00088676\n",
      "2019-01-30 12:06:17,865 epoch 37 - iter 4/23 - loss 0.00086640\n",
      "2019-01-30 12:06:19,864 epoch 37 - iter 6/23 - loss 0.00080490\n",
      "2019-01-30 12:06:21,100 epoch 37 - iter 8/23 - loss 0.00081953\n",
      "2019-01-30 12:06:22,338 epoch 37 - iter 10/23 - loss 0.00078632\n",
      "2019-01-30 12:06:23,808 epoch 37 - iter 12/23 - loss 0.00077411\n",
      "2019-01-30 12:06:24,959 epoch 37 - iter 14/23 - loss 0.00078944\n",
      "2019-01-30 12:06:26,287 epoch 37 - iter 16/23 - loss 0.00078985\n",
      "2019-01-30 12:06:27,322 epoch 37 - iter 18/23 - loss 0.00078652\n",
      "2019-01-30 12:06:28,924 epoch 37 - iter 20/23 - loss 0.00078943\n",
      "2019-01-30 12:06:30,570 epoch 37 - iter 22/23 - loss 0.00079757\n",
      "2019-01-30 12:06:30,580 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:06:30,582 EPOCH 37 done: loss 0.0008 - lr 0.1000 - bad epochs 0\n",
      "2019-01-30 12:06:31,322 DEV  : loss 0.00153407 - f-score 0.8663 - acc 0.8663\n",
      "2019-01-30 12:06:32,370 TEST : loss 0.00128316 - f-score 0.8828 - acc 0.8828\n",
      "2019-01-30 12:06:44,750 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:06:45,416 epoch 38 - iter 0/23 - loss 0.00093495\n",
      "2019-01-30 12:06:46,651 epoch 38 - iter 2/23 - loss 0.00084509\n",
      "2019-01-30 12:06:47,676 epoch 38 - iter 4/23 - loss 0.00083043\n",
      "2019-01-30 12:06:48,878 epoch 38 - iter 6/23 - loss 0.00081057\n",
      "2019-01-30 12:06:50,014 epoch 38 - iter 8/23 - loss 0.00079730\n",
      "2019-01-30 12:06:51,558 epoch 38 - iter 10/23 - loss 0.00078117\n",
      "2019-01-30 12:06:53,305 epoch 38 - iter 12/23 - loss 0.00076325\n",
      "2019-01-30 12:06:54,704 epoch 38 - iter 14/23 - loss 0.00076382\n",
      "2019-01-30 12:06:56,005 epoch 38 - iter 16/23 - loss 0.00076455\n",
      "2019-01-30 12:06:57,396 epoch 38 - iter 18/23 - loss 0.00076772\n",
      "2019-01-30 12:06:59,031 epoch 38 - iter 20/23 - loss 0.00076602\n",
      "2019-01-30 12:07:00,218 epoch 38 - iter 22/23 - loss 0.00079220\n",
      "2019-01-30 12:07:00,228 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:07:00,228 EPOCH 38 done: loss 0.0008 - lr 0.1000 - bad epochs 0\n",
      "2019-01-30 12:07:00,987 DEV  : loss 0.00153647 - f-score 0.8622 - acc 0.8622\n",
      "2019-01-30 12:07:02,029 TEST : loss 0.00127946 - f-score 0.8815 - acc 0.8815\n",
      "2019-01-30 12:07:14,433 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:07:14,942 epoch 39 - iter 0/23 - loss 0.00062641\n",
      "2019-01-30 12:07:16,856 epoch 39 - iter 2/23 - loss 0.00074749\n",
      "2019-01-30 12:07:18,120 epoch 39 - iter 4/23 - loss 0.00073342\n",
      "2019-01-30 12:07:19,820 epoch 39 - iter 6/23 - loss 0.00073566\n",
      "2019-01-30 12:07:21,040 epoch 39 - iter 8/23 - loss 0.00072478\n",
      "2019-01-30 12:07:22,267 epoch 39 - iter 10/23 - loss 0.00075813\n",
      "2019-01-30 12:07:23,421 epoch 39 - iter 12/23 - loss 0.00075597\n",
      "2019-01-30 12:07:24,933 epoch 39 - iter 14/23 - loss 0.00075375\n",
      "2019-01-30 12:07:26,146 epoch 39 - iter 16/23 - loss 0.00075835\n",
      "2019-01-30 12:07:27,944 epoch 39 - iter 18/23 - loss 0.00077852\n",
      "2019-01-30 12:07:29,649 epoch 39 - iter 20/23 - loss 0.00078493\n",
      "2019-01-30 12:07:30,346 epoch 39 - iter 22/23 - loss 0.00081326\n",
      "2019-01-30 12:07:30,357 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:07:30,358 EPOCH 39 done: loss 0.0008 - lr 0.1000 - bad epochs 0\n",
      "2019-01-30 12:07:31,116 DEV  : loss 0.00151506 - f-score 0.8690 - acc 0.8690\n",
      "2019-01-30 12:07:32,172 TEST : loss 0.00126734 - f-score 0.8883 - acc 0.8883\n",
      "2019-01-30 12:07:32,175 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:07:32,843 epoch 40 - iter 0/23 - loss 0.00085348\n",
      "2019-01-30 12:07:34,188 epoch 40 - iter 2/23 - loss 0.00080118\n",
      "2019-01-30 12:07:35,668 epoch 40 - iter 4/23 - loss 0.00077922\n",
      "2019-01-30 12:07:36,741 epoch 40 - iter 6/23 - loss 0.00081258\n",
      "2019-01-30 12:07:37,837 epoch 40 - iter 8/23 - loss 0.00080635\n",
      "2019-01-30 12:07:38,931 epoch 40 - iter 10/23 - loss 0.00077881\n",
      "2019-01-30 12:07:40,113 epoch 40 - iter 12/23 - loss 0.00076900\n",
      "2019-01-30 12:07:41,622 epoch 40 - iter 14/23 - loss 0.00077584\n",
      "2019-01-30 12:07:43,472 epoch 40 - iter 16/23 - loss 0.00077698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-30 12:07:44,717 epoch 40 - iter 18/23 - loss 0.00076388\n",
      "2019-01-30 12:07:46,516 epoch 40 - iter 20/23 - loss 0.00076420\n",
      "2019-01-30 12:07:47,560 epoch 40 - iter 22/23 - loss 0.00077355\n",
      "2019-01-30 12:07:47,570 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:07:47,570 EPOCH 40 done: loss 0.0008 - lr 0.1000 - bad epochs 1\n",
      "2019-01-30 12:07:48,320 DEV  : loss 0.00153057 - f-score 0.8690 - acc 0.8690\n",
      "2019-01-30 12:07:49,371 TEST : loss 0.00128393 - f-score 0.8869 - acc 0.8869\n",
      "2019-01-30 12:08:14,256 ----------------------------------------------------------------------------------------------------\n",
      "2019-01-30 12:08:14,257 Testing using best model ...\n",
      "2019-01-30 12:08:18,034 MICRO_AVG: acc 0.8869 - f1-score 0.8869\n",
      "2019-01-30 12:08:18,036 MARCO_AVG: acc 0.8823 - f1-score 0.8883\n",
      "2019-01-30 12:08:18,037 roteador   tp: 229 - fp: 39 - fn: 27 - tn: 229 - precision: 0.8545 - recall: 0.8945 - accuracy: 0.8740 - f1-score: 0.8740\n",
      "2019-01-30 12:08:18,037 territorio tp: 150 - fp: 16 - fn: 34 - tn: 150 - precision: 0.9036 - recall: 0.8152 - accuracy: 0.8571 - f1-score: 0.8571\n",
      "2019-01-30 12:08:18,038 transacional tp: 272 - fp: 28 - fn: 22 - tn: 272 - precision: 0.9067 - recall: 0.9252 - accuracy: 0.9158 - f1-score: 0.9159\n",
      "2019-01-30 12:08:18,039 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8869,\n",
       " 'dev_score_history': [0.8308,\n",
       "  0.8608,\n",
       "  0.8608,\n",
       "  0.8649,\n",
       "  0.854,\n",
       "  0.8445,\n",
       "  0.8636,\n",
       "  0.8704,\n",
       "  0.869,\n",
       "  0.8145,\n",
       "  0.8377,\n",
       "  0.8677,\n",
       "  0.8649,\n",
       "  0.8608,\n",
       "  0.8718,\n",
       "  0.869,\n",
       "  0.8704,\n",
       "  0.869,\n",
       "  0.8663,\n",
       "  0.8649,\n",
       "  0.8731,\n",
       "  0.869,\n",
       "  0.8704,\n",
       "  0.8786,\n",
       "  0.8677,\n",
       "  0.8745,\n",
       "  0.8622,\n",
       "  0.8513,\n",
       "  0.8799,\n",
       "  0.8731,\n",
       "  0.8759,\n",
       "  0.8527,\n",
       "  0.869,\n",
       "  0.8267,\n",
       "  0.8636,\n",
       "  0.8718,\n",
       "  0.8663,\n",
       "  0.8622,\n",
       "  0.869,\n",
       "  0.869],\n",
       " 'train_loss_history': [0.001338981084201647,\n",
       "  0.0013715804504311603,\n",
       "  0.001331384767656741,\n",
       "  0.0012721255032912544,\n",
       "  0.001525591871012812,\n",
       "  0.001286069973655369,\n",
       "  0.0012143228183621945,\n",
       "  0.0012192929257517275,\n",
       "  0.001231595049733701,\n",
       "  0.0012087140523869058,\n",
       "  0.0012578189761742302,\n",
       "  0.0012096657234689464,\n",
       "  0.0011095874776010928,\n",
       "  0.0011044908865638402,\n",
       "  0.0011333272560783054,\n",
       "  0.0012639057636260986,\n",
       "  0.0010811760477397753,\n",
       "  0.0012057346338811127,\n",
       "  0.0010496937399325163,\n",
       "  0.0010681828208591627,\n",
       "  0.0010692540666331417,\n",
       "  0.0011390895091969034,\n",
       "  0.00098733658635098,\n",
       "  0.000991988568202309,\n",
       "  0.0009744534829388494,\n",
       "  0.0011197066695793816,\n",
       "  0.000952380068924116,\n",
       "  0.0009149210090222566,\n",
       "  0.0010449075672937477,\n",
       "  0.0008797827285269033,\n",
       "  0.0009510901362999626,\n",
       "  0.0009138668153596962,\n",
       "  0.0009031676079915917,\n",
       "  0.0009443977345591006,\n",
       "  0.0008759629596834597,\n",
       "  0.0008192697659782742,\n",
       "  0.0007975674608479375,\n",
       "  0.0007922043411628059,\n",
       "  0.000813261752543242,\n",
       "  0.0007735499869222227],\n",
       " 'dev_loss_history': [0.0017830124124884605,\n",
       "  0.001644879230298102,\n",
       "  0.0016069745179265738,\n",
       "  0.001664156443439424,\n",
       "  0.0017373411683365703,\n",
       "  0.0017391571309417486,\n",
       "  0.001602817210368812,\n",
       "  0.0015814128564670682,\n",
       "  0.001617314526811242,\n",
       "  0.002096334472298622,\n",
       "  0.0017378450138494372,\n",
       "  0.0015461714938282967,\n",
       "  0.0016017223242670298,\n",
       "  0.0015824370784685016,\n",
       "  0.0015105657512322068,\n",
       "  0.0015384642174467444,\n",
       "  0.0015450948849320412,\n",
       "  0.001585214864462614,\n",
       "  0.0015183822251856327,\n",
       "  0.0017656780546531081,\n",
       "  0.001560358563438058,\n",
       "  0.00150537327863276,\n",
       "  0.0015647996915504336,\n",
       "  0.001585002988576889,\n",
       "  0.001590769737958908,\n",
       "  0.0015071179950609803,\n",
       "  0.0015462361043319106,\n",
       "  0.0016004506032913923,\n",
       "  0.001511655398644507,\n",
       "  0.0016475674929097295,\n",
       "  0.0015888161724433303,\n",
       "  0.0018138096202164888,\n",
       "  0.0015289672883227468,\n",
       "  0.0021122670732438564,\n",
       "  0.0015132467960938811,\n",
       "  0.0015074145048856735,\n",
       "  0.0015340748941525817,\n",
       "  0.0015364651335403323,\n",
       "  0.0015150579856708646,\n",
       "  0.001530568697489798]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. start the training\n",
    "trainer.train('./',\n",
    "              learning_rate=0.2,\n",
    "              mini_batch_size=256,\n",
    "              max_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 8. plot training curves (optional)\n",
    "# from flair.visual.training_curves import Plotter\n",
    "# plotter = Plotter()\n",
    "# plotter.plot_training_curves('resources/flair_test/loss.tsv')\n",
    "# plotter.plot_weights('resources/flair_test/weights.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flair",
   "language": "python",
   "name": "flair"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
